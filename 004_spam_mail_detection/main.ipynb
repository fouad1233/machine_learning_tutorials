{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of       Unnamed: 0 label                                               text  \\\n",
      "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
      "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
      "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
      "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
      "...          ...   ...                                                ...   \n",
      "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
      "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
      "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
      "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
      "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
      "\n",
      "      label_num  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             1  \n",
      "4             0  \n",
      "...         ...  \n",
      "5166          0  \n",
      "5167          0  \n",
      "5168          0  \n",
      "5169          0  \n",
      "5170          1  \n",
      "\n",
      "[5171 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of      label                                               text\n",
      "0      ham  Subject: enron methanol ; meter # : 988291\\r\\n...\n",
      "1      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
      "2      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
      "3     spam  Subject: photoshop , windows , office . cheap ...\n",
      "4      ham  Subject: re : indian springs\\r\\nthis deal is t...\n",
      "...    ...                                                ...\n",
      "5166   ham  Subject: put the 10 on the ft\\r\\nthe transport...\n",
      "5167   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...\n",
      "5168   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...\n",
      "5169   ham  Subject: industrial worksheets for august 2000...\n",
      "5170  spam  Subject: important online banking alert\\r\\ndea...\n",
      "\n",
      "[5171 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = df.drop([\"Unnamed: 0\", \"label_num\"], axis=1)\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of      label                                               text\n",
      "0      ham  Subject: enron methanol ; meter # : 988291\\r\\n...\n",
      "1      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
      "2      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
      "3     spam  Subject: photoshop , windows , office . cheap ...\n",
      "4      ham  Subject: re : indian springs\\r\\nthis deal is t...\n",
      "...    ...                                                ...\n",
      "5166   ham  Subject: put the 10 on the ft\\r\\nthe transport...\n",
      "5167   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...\n",
      "5168   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...\n",
      "5169   ham  Subject: industrial worksheets for august 2000...\n",
      "5170  spam  Subject: important online banking alert\\r\\ndea...\n",
      "\n",
      "[5171 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "df.columns = ['label', 'text']\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text  b_labels\n",
      "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...         0\n",
      "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...         0\n",
      "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...         0\n",
      "3  spam  Subject: photoshop , windows , office . cheap ...         1\n",
      "4   ham  Subject: re : indian springs\\r\\nthis deal is t...         0\n"
     ]
    }
   ],
   "source": [
    "df['b_labels'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['b_labels'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4191    Subject: uqfcavegwo our team is ready\\r\\npoohb...\n",
      "5026    Subject: issues\\r\\nvalero has accepted this pr...\n",
      "3525    Subject: \\r\\nthe only fix to penis growth\\r\\nl...\n",
      "2924    Subject: re : path manager rewrite / optimizat...\n",
      "4155    Subject: sarco lateral and crow o ' connor met...\n",
      "                              ...                        \n",
      "4052    Subject: methanol plant status\\r\\nit now appea...\n",
      "534     Subject: this has worked for me marrow enemy\\r...\n",
      "4158    Subject: mary poorman interview schedule\\r\\npl...\n",
      "3567    Subject: ever tried this before ?\\r\\nenjoy sto...\n",
      "2140    Subject: buy office xp for fifty bucks percent...\n",
      "Name: text, Length: 3464, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(decode_error='ignore')\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 302826 stored elements and shape (3464, 40366)>\n",
      "  Coords\tValues\n",
      "  (0, 34995)\t0.01337504100952336\n",
      "  (0, 37595)\t0.11311701160867386\n",
      "  (0, 27721)\t0.034824360224827385\n",
      "  (0, 35724)\t0.0582439883538578\n",
      "  (0, 21428)\t0.04646758288142771\n",
      "  (0, 30857)\t0.06575653543662068\n",
      "  (0, 29262)\t0.11311701160867386\n",
      "  (0, 27931)\t0.11311701160867386\n",
      "  (0, 22251)\t0.11311701160867386\n",
      "  (0, 23053)\t0.08616760107870858\n",
      "  (0, 33026)\t0.08231984156196134\n",
      "  (0, 27160)\t0.0697740428413008\n",
      "  (0, 27357)\t0.04487055610973329\n",
      "  (0, 23562)\t0.05256541032957188\n",
      "  (0, 24902)\t0.07562195154957593\n",
      "  (0, 20280)\t0.11311701160867386\n",
      "  (0, 13494)\t0.09842302719417158\n",
      "  (0, 33673)\t0.07881070876527521\n",
      "  (0, 32949)\t0.07006441544649834\n",
      "  (0, 5324)\t0.08658358306833365\n",
      "  (0, 13605)\t0.08300589147790839\n",
      "  (0, 33481)\t0.07483495744874834\n",
      "  (0, 36020)\t0.2004835905026621\n",
      "  (0, 7333)\t0.0503700412939185\n",
      "  (0, 30539)\t0.11311701160867386\n",
      "  :\t:\n",
      "  (3463, 36901)\t0.09736811935769064\n",
      "  (3463, 10)\t0.06491207957179376\n",
      "  (3463, 4566)\t0.03245603978589688\n",
      "  (3463, 26147)\t0.09736811935769064\n",
      "  (3463, 7435)\t0.03245603978589688\n",
      "  (3463, 35710)\t0.09736811935769064\n",
      "  (3463, 7880)\t0.03245603978589688\n",
      "  (3463, 17043)\t0.09736811935769064\n",
      "  (3463, 8287)\t0.09736811935769064\n",
      "  (3463, 11586)\t0.03245603978589688\n",
      "  (3463, 20667)\t0.12982415914358753\n",
      "  (3463, 1096)\t0.12982415914358753\n",
      "  (3463, 1514)\t0.12982415914358753\n",
      "  (3463, 35500)\t0.06491207957179376\n",
      "  (3463, 25822)\t0.03245603978589688\n",
      "  (3463, 8814)\t0.03245603978589688\n",
      "  (3463, 25575)\t0.03245603978589688\n",
      "  (3463, 8813)\t0.03245603978589688\n",
      "  (3463, 35496)\t0.03245603978589688\n",
      "  (3463, 7807)\t0.03245603978589688\n",
      "  (3463, 14646)\t0.03245603978589688\n",
      "  (3463, 4016)\t0.03245603978589688\n",
      "  (3463, 14862)\t0.03245603978589688\n",
      "  (3463, 7856)\t0.03245603978589688\n",
      "  (3463, 12167)\t0.03245603978589688\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9136836027713626\n",
      "test score: 0.8506151142355008\n"
     ]
    }
   ],
   "source": [
    "#classify using naive bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "print(\"train accuracy:\", model.score(x_train, y_train))\n",
    "print(\"test score:\", model.score(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def fit(self, X, y):\n",
    "        # Separate documents by class\n",
    "        self.spam_docs = X[y == 1]\n",
    "        self.ham_docs = X[y == 0]\n",
    "        \n",
    "        # Calculate the prior probabilities P(spam) and P(ham)\n",
    "        self.p_spam = len(self.spam_docs) / len(X)\n",
    "        self.p_ham = len(self.ham_docs) / len(X)\n",
    "        \n",
    "        # Calculate word counts for spam and ham\n",
    "        self.spam_word_count = np.sum(self.spam_docs, axis=0)\n",
    "        self.ham_word_count = np.sum(self.ham_docs, axis=0)\n",
    "        #print(self.spam_word_count)\n",
    "        # Total word counts for spam and ham documents\n",
    "        self.spam_total = np.sum(self.spam_word_count)\n",
    "        self.ham_total = np.sum(self.ham_word_count)\n",
    "        \n",
    "        # Vocabulary size\n",
    "        self.vocab_size = X.shape[1]\n",
    "        \n",
    "        # Calculate conditional probabilities with Laplace smoothing\n",
    "        self.spam_prob = (self.spam_word_count + 1) / (self.spam_total + self.vocab_size)\n",
    "        self.ham_prob = (self.ham_word_count + 1) / (self.ham_total + self.vocab_size)\n",
    "    \n",
    "    def predict_log_proba(self, X):\n",
    "        # Calculate log probabilities for the given X based on learned probabilities\n",
    "        log_prob_spam = X @ np.log(self.spam_prob) + np.log(self.p_spam)\n",
    "        log_prob_ham = X @ np.log(self.ham_prob) + np.log(self.p_ham)\n",
    "        \n",
    "        # Combine into a matrix of log probabilities for each class\n",
    "        return np.vstack([log_prob_ham, log_prob_spam]).T\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Get the log probabilities for ham and spam\n",
    "        log_probs = self.predict_log_proba(X)\n",
    "        \n",
    "        # Choose the class with the higher probability (log space)\n",
    "        return np.argmax(log_probs, axis=1)\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        # Predict and check the accuracy\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "    def precision(self, X, y):\n",
    "        # Predict and check the precision\n",
    "        predictions = self.predict(X)\n",
    "        return np.sum(predictions[y == 1] == 1) / np.sum(predictions == 1)\n",
    "    def recall(self, X, y):\n",
    "        # Predict and check the recall\n",
    "        predictions = self.predict(X)\n",
    "        return np.sum(predictions[y == 1] == 1) / np.sum(y == 1)\n",
    "    def f1_score(self, X, y):\n",
    "        # Calculate the F1 score\n",
    "        precision = self.precision(X, y)\n",
    "        recall = self.recall(X, y)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def fit(self, X, y):\n",
    "        # Separate documents by class\n",
    "        self.C = [X[y == i] for i in np.unique(y)]\n",
    "        \n",
    "        # Calculate the prior probabilities P(spam) and P(ham)\n",
    "        self.p_C = [len(self.C[i]) / len(X) for i in range(len(np.unique(y)))]\n",
    "        \n",
    "        # Calculate word counts for spam and ham\n",
    "        self.C_count = [np.sum(self.C[i], axis=0) for i in range(len(np.unique(y)))]\n",
    "        \n",
    "        self.c_total = [np.sum(self.C_count[i]) for i in range(len(np.unique(y)))]\n",
    "        \n",
    "        # Vocabulary size\n",
    "        self.vocab_size = X.shape[1]\n",
    "        \n",
    "        # Calculate conditional probabilities with Laplace smoothing\n",
    "        self.C_prob = [(self.C_count[i] + 1) / (self.c_total[i] + self.vocab_size) for i in range(len(np.unique(y)))]\n",
    "    \n",
    "    def predict_log_proba(self, X):\n",
    "        \n",
    "        log_prob_C = [X @ np.log(self.C_prob[i]) + np.log(self.p_C[i]) for i in range(len(np.unique(y)))]\n",
    "        \n",
    "        # Combine into a matrix of log probabilities for each class\n",
    "        return np.vstack(log_prob_C).T\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Get the log probabilities for ham and spam\n",
    "        log_probs = self.predict_log_proba(X)\n",
    "        \n",
    "        # Choose the class with the higher probability (log space)\n",
    "        return np.argmax(log_probs, axis=1)\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        # Predict and check the accuracy\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "    def precision(self, X, y):\n",
    "        # Predict and check the precision\n",
    "        predictions = self.predict(X)\n",
    "        return np.sum(predictions[y == 1] == 1) / np.sum(predictions == 1)\n",
    "    def recall(self, X, y):\n",
    "        # Predict and check the recall\n",
    "        predictions = self.predict(X)\n",
    "        return np.sum(predictions[y == 1] == 1) / np.sum(y == 1)\n",
    "    def f1_score(self, X, y):\n",
    "        # Calculate the F1 score\n",
    "        precision = self.precision(X, y)\n",
    "        recall = self.recall(X, y)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform xtrain to numpy array\n",
    "x_train = x_train.toarray()\n",
    "x_test = x_test.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9136836027713626\n",
      "train precision: 1.0\n",
      "train recall: 0.697979797979798\n",
      "train f1 score: 0.8221296847114814\n",
      "test accuracy: 0.8506151142355008\n",
      "test precision: 1.0\n",
      "test recall: 0.49901768172888017\n",
      "test f1 score: 0.6657929226736565\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the Naive Bayes Classifier\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "# Calculate training and test accuracy\n",
    "print(\"train accuracy:\", nb.accuracy(x_train, y_train))\n",
    "print(\"train precision:\", nb.precision(x_train, y_train))\n",
    "print(\"train recall:\", nb.recall(x_train, y_train))\n",
    "print(\"train f1 score:\", nb.f1_score(x_train, y_train))\n",
    "print(\"test accuracy:\", nb.accuracy(x_test, y_test))\n",
    "print(\"test precision:\", nb.precision(x_test, y_test))\n",
    "print(\"test recall:\", nb.recall(x_test, y_test))\n",
    "print(\"test f1 score:\", nb.f1_score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
