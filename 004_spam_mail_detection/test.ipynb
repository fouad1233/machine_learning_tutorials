{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of       Unnamed: 0 label                                               text  \\\n",
      "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
      "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
      "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
      "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
      "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
      "...          ...   ...                                                ...   \n",
      "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
      "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
      "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
      "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
      "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
      "\n",
      "      label_num  \n",
      "0             0  \n",
      "1             0  \n",
      "2             0  \n",
      "3             1  \n",
      "4             0  \n",
      "...         ...  \n",
      "5166          0  \n",
      "5167          0  \n",
      "5168          0  \n",
      "5169          0  \n",
      "5170          1  \n",
      "\n",
      "[5171 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of      label                                               text\n",
      "0      ham  Subject: enron methanol ; meter # : 988291\\r\\n...\n",
      "1      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
      "2      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
      "3     spam  Subject: photoshop , windows , office . cheap ...\n",
      "4      ham  Subject: re : indian springs\\r\\nthis deal is t...\n",
      "...    ...                                                ...\n",
      "5166   ham  Subject: put the 10 on the ft\\r\\nthe transport...\n",
      "5167   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...\n",
      "5168   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...\n",
      "5169   ham  Subject: industrial worksheets for august 2000...\n",
      "5170  spam  Subject: important online banking alert\\r\\ndea...\n",
      "\n",
      "[5171 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "df = df.drop([\"Unnamed: 0\", \"label_num\"], axis=1)\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.describe of      label                                               text\n",
      "0      ham  Subject: enron methanol ; meter # : 988291\\r\\n...\n",
      "1      ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
      "2      ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
      "3     spam  Subject: photoshop , windows , office . cheap ...\n",
      "4      ham  Subject: re : indian springs\\r\\nthis deal is t...\n",
      "...    ...                                                ...\n",
      "5166   ham  Subject: put the 10 on the ft\\r\\nthe transport...\n",
      "5167   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...\n",
      "5168   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...\n",
      "5169   ham  Subject: industrial worksheets for august 2000...\n",
      "5170  spam  Subject: important online banking alert\\r\\ndea...\n",
      "\n",
      "[5171 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "df.columns = ['label', 'text']\n",
    "print(df.describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text  b_labels\n",
      "0   ham  Subject: enron methanol ; meter # : 988291\\r\\n...         0\n",
      "1   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...         0\n",
      "2   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...         0\n",
      "3  spam  Subject: photoshop , windows , office . cheap ...         1\n",
      "4   ham  Subject: re : indian springs\\r\\nthis deal is t...         0\n"
     ]
    }
   ],
   "source": [
    "df['b_labels'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['b_labels'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531     Subject: solid loans made simple\\r\\nmaybe not ...\n",
      "733     Subject: correction on first delivery for cody...\n",
      "805     Subject: march preliminary wellhead production...\n",
      "2430    Subject: cilco pathing - withdrawl and hplc tr...\n",
      "4327    Subject: neon discussion january 17\\r\\nhere ' ...\n",
      "                              ...                        \n",
      "985     Subject: correction to 4 / 5 / 00 nominations ...\n",
      "1033    Subject: april 1 noms\\r\\n- - - - - - - - - - -...\n",
      "2211    Subject: re : noms / actual flow for 4 / 01 / ...\n",
      "3294    Subject: re : 98 - 6892 for 3 / 15 / 2000 and ...\n",
      "3762    Subject: tejas deliveries at oasis katy\\r\\non ...\n",
      "Name: text, Length: 3464, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(decode_error='ignore')\n",
    "x_train = tfidf.fit_transform(x_train)\n",
    "x_test = tfidf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 307857 stored elements and shape (3464, 41217)>\n",
      "  Coords\tValues\n",
      "  (0, 35750)\t0.047468238637046606\n",
      "  (0, 34811)\t0.30908519137058166\n",
      "  (0, 24118)\t0.3300582138934262\n",
      "  (0, 24577)\t0.18681277945055494\n",
      "  (0, 34351)\t0.2797004905002666\n",
      "  (0, 25076)\t0.2616867865768957\n",
      "  (0, 27261)\t0.10914291338479587\n",
      "  (0, 36962)\t0.0876879756705654\n",
      "  (0, 37129)\t0.14352490594010656\n",
      "  (0, 20319)\t0.14854922128345274\n",
      "  (0, 36344)\t0.4014541186921902\n",
      "  (0, 24322)\t0.4014541186921902\n",
      "  (0, 31338)\t0.23135078656117963\n",
      "  (0, 10879)\t0.12427819142943229\n",
      "  (0, 31894)\t0.3164024526266849\n",
      "  (0, 29257)\t0.24080307403079598\n",
      "  (1, 35750)\t0.03550364543339432\n",
      "  (1, 11762)\t0.21204247192303666\n",
      "  (1, 27827)\t0.05937268297174696\n",
      "  (1, 17044)\t0.13242621561048326\n",
      "  (1, 13127)\t0.1453598099867772\n",
      "  (1, 17354)\t0.04813033087296074\n",
      "  (1, 10731)\t0.23380991574202384\n",
      "  (1, 21838)\t0.07666270292145798\n",
      "  (1, 34191)\t0.09811746950342062\n",
      "  :\t:\n",
      "  (3463, 37531)\t0.06223588909443339\n",
      "  (3463, 11936)\t0.1263527213894248\n",
      "  (3463, 3938)\t0.055957564421242376\n",
      "  (3463, 5253)\t0.03669332423918757\n",
      "  (3463, 18035)\t0.0741395890006288\n",
      "  (3463, 36619)\t0.44051719094041264\n",
      "  (3463, 22685)\t0.1930941729153283\n",
      "  (3463, 25954)\t0.15059678060889167\n",
      "  (3463, 37876)\t0.05890575641808452\n",
      "  (3463, 13124)\t0.06013976945509597\n",
      "  (3463, 9329)\t0.060400911422926425\n",
      "  (3463, 9868)\t0.06668673022362703\n",
      "  (3463, 28197)\t0.07451476349031153\n",
      "  (3463, 16254)\t0.0741395890006288\n",
      "  (3463, 29859)\t0.08196762226731329\n",
      "  (3463, 39424)\t0.09260199896032185\n",
      "  (3463, 33725)\t0.07116780476795206\n",
      "  (3463, 38502)\t0.07656771351763267\n",
      "  (3463, 14915)\t0.09260199896032185\n",
      "  (3463, 27475)\t0.0877047088656502\n",
      "  (3463, 5678)\t0.08010629876397833\n",
      "  (3463, 23390)\t0.4136072658387323\n",
      "  (3463, 984)\t0.107233112689849\n",
      "  (3463, 985)\t0.107233112689849\n",
      "  (3463, 2661)\t0.107233112689849\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9110854503464203\n",
      "test score: 0.8670181605155243\n"
     ]
    }
   ],
   "source": [
    "#classify using naive bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "print(\"train accuracy:\", model.score(x_train, y_train))\n",
    "print(\"test score:\", model.score(x_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def fit(self, X, y):\n",
    "        # Separate documents by class\n",
    "        self.spam_docs = X[y == 1]\n",
    "        self.ham_docs = X[y == 0]\n",
    "        \n",
    "        # Calculate the prior probabilities P(spam) and P(ham)\n",
    "        self.p_spam = len(self.spam_docs) / len(X)\n",
    "        self.p_ham = len(self.ham_docs) / len(X)\n",
    "        \n",
    "        # Calculate word counts for spam and ham this is the frequency of each word appears in each class\n",
    "        self.spam_word_count = np.sum(self.spam_docs, axis=0)\n",
    "        self.ham_word_count = np.sum(self.ham_docs, axis=0)\n",
    "        #print(self.spam_word_count)\n",
    "        # Total word counts for spam and ham documents\n",
    "        self.spam_total = np.sum(self.spam_word_count)\n",
    "        self.ham_total = np.sum(self.ham_word_count)\n",
    "        \n",
    "        # Vocabulary size\n",
    "        self.vocab_size = X.shape[1] # This is the number of unique words\n",
    "        \n",
    "        # Calculate conditional probabilities with Laplace smoothing\n",
    "        self.spam_prob = (self.spam_word_count + 1) / (self.spam_total + self.vocab_size)\n",
    "        self.ham_prob = (self.ham_word_count + 1) / (self.ham_total + self.vocab_size)\n",
    "    \n",
    "    def predict_log_proba(self, X):\n",
    "        # Calculate log probabilities for the given X based on learned probabilities\n",
    "        log_prob_spam = X @ np.log(self.spam_prob) + np.log(self.p_spam)\n",
    "        log_prob_ham = X @ np.log(self.ham_prob) + np.log(self.p_ham)\n",
    "        \n",
    "        # Combine into a matrix of log probabilities for each class\n",
    "        return np.vstack([log_prob_ham, log_prob_spam]).T\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Get the log probabilities for ham and spam\n",
    "        log_probs = self.predict_log_proba(X)\n",
    "        \n",
    "        # Choose the class with the higher probability (log space)\n",
    "        return np.argmax(log_probs, axis=1)\n",
    "    \n",
    "    def accuracy(self, X, y):\n",
    "        # Predict and check the accuracy\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "    def precision(self, X, y):\n",
    "        # Predict and check the precision\n",
    "        predictions = self.predict(X)\n",
    "        return np.sum(predictions[y == 1] == 1) / np.sum(predictions == 1)\n",
    "    def recall(self, X, y):\n",
    "        # Predict and check the recall\n",
    "        predictions = self.predict(X)\n",
    "        return np.sum(predictions[y == 1] == 1) / np.sum(y == 1)\n",
    "    def f1_score(self, X, y):\n",
    "        # Calculate the F1 score\n",
    "        precision = self.precision(X, y)\n",
    "        recall = self.recall(X, y)\n",
    "        return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform xtrain to numpy array\n",
    "x_train = x_train.toarray()\n",
    "x_test = x_test.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.9110854503464203\n",
      "train precision: 1.0\n",
      "train recall: 0.692\n",
      "train f1 score: 0.817966903073286\n",
      "test accuracy: 0.8670181605155243\n",
      "test precision: 1.0\n",
      "test recall: 0.5450901803607214\n",
      "test f1 score: 0.7055771725032425\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and train the Naive Bayes Classifier\n",
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(x_train, y_train)\n",
    "\n",
    "# Calculate training and test accuracy\n",
    "print(\"train accuracy:\", nb.accuracy(x_train, y_train))\n",
    "print(\"train precision:\", nb.precision(x_train, y_train))\n",
    "print(\"train recall:\", nb.recall(x_train, y_train))\n",
    "print(\"train f1 score:\", nb.f1_score(x_train, y_train))\n",
    "print(\"test accuracy:\", nb.accuracy(x_test, y_test))\n",
    "print(\"test precision:\", nb.precision(x_test, y_test))\n",
    "print(\"test recall:\", nb.recall(x_test, y_test))\n",
    "print(\"test f1 score:\", nb.f1_score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
